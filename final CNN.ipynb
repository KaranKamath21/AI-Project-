{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJfZHazJl0ly",
        "outputId": "8de657ba-4c70-4234-e12d-6095f3031c0d"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# %pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "N3iJMHI5lZ0q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "MWMLf9qclZ0v",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_path = Path('/Users/karankamath/Desktop/ARC-master/data')\n",
        "train_path = data_path / 'training'\n",
        "eval_path = data_path / 'evaluation'\n",
        "test_path = data_path / 'test'\n",
        "\n",
        "train_tasks = { task.stem: json.load(task.open()) for task in train_path.iterdir() }\n",
        "eval_tasks = { task.stem: json.load(task.open()) for task in eval_path.iterdir() }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "M1T_nhPhlZ0w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "cmap = colors.ListedColormap(\n",
        "        ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
        "         '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
        "norm = colors.Normalize(vmin=0, vmax=9)\n",
        "\n",
        "def plot_pictures(pictures, labels):\n",
        "    # print(len(pictures))\n",
        "    fig, axs = plt.subplots(1, len(pictures), figsize=(2*len(pictures),32))\n",
        "    for i, (pict, label) in enumerate(zip(pictures, labels)):\n",
        "        axs[i].imshow(np.array(pict), cmap=cmap, norm=norm)\n",
        "        axs[i].set_title(label)\n",
        "    plt.show()\n",
        "\n",
        "def plot_sample(sample, predict=None):\n",
        "    if predict is None:\n",
        "        plot_pictures([sample['input'], sample['output']], ['Input', 'Output'])\n",
        "    elif 'output' in sample:\n",
        "        plot_pictures([sample['input'], sample['output'], predict], ['Input', 'Output', 'Predict'])\n",
        "    else:\n",
        "        plot_pictures([sample['input'], predict], ['Input', 'Predict'])\n",
        "\n",
        "def inp2img(inp):\n",
        "    inp = np.array(inp)\n",
        "    img = np.full((10, inp.shape[0], inp.shape[1]), 0, dtype=np.uint8)\n",
        "    for i in range(10):\n",
        "        img[i] = (inp==i)\n",
        "    return img\n",
        "\n",
        "def input_output_shape_is_same(task):\n",
        "    return all([np.array(el['input']).shape == np.array(el['output']).shape for el in task['train']])\n",
        "\n",
        "\n",
        "def calk_score(task_test, predict):\n",
        "    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugAxzY8glZ0y"
      },
      "source": [
        "## Checking for 5 tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "3SV6rvQ3lZ0z",
        "outputId": "71075ae9-166a-49b4-e8b8-419eac4e70a4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "task = train_tasks[\"db3e9e38\"][\"train\"]\n",
        "for sample in task:\n",
        "    plot_sample(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "fYPUQ1SXxiay",
        "outputId": "2b7c1c79-8ce9-4291-9b2d-d67b338e4ffe"
      },
      "outputs": [],
      "source": [
        "task = train_tasks[\"7ddcd7ec\"][\"train\"]\n",
        "for sample in task:\n",
        "    plot_sample(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yh8ODbUlZ01"
      },
      "source": [
        "## The Model\n",
        "\n",
        "The model consists of a single 3x3 convolutional layer, followed by a 1x1 convolutional layer, just like my last notebook. Here `num_states` represents how many values a single cell could have; in this case 10, one for each color. Down the road, we may want to add a hidden state, concatinating it to the input, then removing it from the output.\n",
        "\n",
        "The foward pass of the model will repeatedly pass the grid state through the CA transition for `steps` number of times."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RvkhrjOlZ03",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CAModel(nn.Module):\n",
        "    def __init__(self, num_states):\n",
        "        super(CAModel, self).__init__()\n",
        "        self.transition = nn.Sequential(\n",
        "            nn.Conv2d(num_states, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, num_states, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, steps=1):\n",
        "        for _ in range(steps):\n",
        "            x = self.transition(torch.softmax(x, dim=1))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLMhqo-ylZ05"
      },
      "source": [
        "## Training\n",
        "\n",
        "This \"recurrent CNN\" can be quite to difficult to train. After trying a few ideas, this seemed to be the best approach that I encountered:\n",
        "\n",
        "* For every value $n$ = $1, ..., N$:\n",
        "    1. Train the model with $n$ `steps` to produce the output from input\n",
        "    2. Train the model with 1 `steps` to produce output from output\n",
        "        * This enforces that the CA stabilizes after reaching a solution\n",
        "        \n",
        "In this way the model will try to get as close to a solution as possible in 1 step, then try to get closer in the next step, and so on until $N$ steps. For now I will use $N = 10$ = `max_steps`. I will also set the learning rate to decay with each additional step: $LR = 0.1 / (n * 2) $"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO2vriH5lZ07",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "\n",
        "def solve_task(task, max_steps=12):\n",
        "    model = CAModel(10).to(device)\n",
        "    num_epochs = 100\n",
        "    num_repeat = 10\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    losses = np.zeros((num_repeat - 1) * num_epochs)\n",
        "\n",
        "    for i in range(1, num_repeat):\n",
        "        if i > num_repeat-4:\n",
        "            num_steps = max_steps\n",
        "        else:\n",
        "            num_steps = random.randint(1, max_steps)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=(0.04 / i))\n",
        "\n",
        "        for e in range(num_epochs):\n",
        "            optimizer.zero_grad()\n",
        "            loss = 0.0\n",
        "\n",
        "            for sample in task:\n",
        "                # predict output from input\n",
        "                x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n",
        "                y = torch.tensor(sample[\"output\"]).long().unsqueeze(0).to(device)\n",
        "                y_pred = model(x, num_steps)\n",
        "                loss += criterion(y_pred, y)\n",
        "\n",
        "                # predit output from output\n",
        "                # enforces stability after solution is reached\n",
        "                y_in = torch.from_numpy(inp2img(sample[\"output\"])).unsqueeze(0).float().to(device)\n",
        "                y_pred = model(y_in, 1)\n",
        "                loss += criterion(y_pred, y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            losses[(i - 1) * num_epochs + e] = loss.item()\n",
        "    return model, num_steps, losses\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(model, task):\n",
        "    predictions = []\n",
        "    for sample in task:\n",
        "        x = torch.from_numpy(inp2img(sample[\"input\"])).unsqueeze(0).float().to(device)\n",
        "        pred = model(x, 200).argmax(1).squeeze().cpu().numpy()\n",
        "        predictions.append(pred)\n",
        "    return predictions\n",
        "\n",
        "task = train_tasks[\"dbc1a6ce\"][\"train\"]\n",
        "model, num_steps, losses = solve_task(task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klxGi-MilZ08"
      },
      "source": [
        "$n$ is incremented every 100 epochs, so we can see that it reaches a good solution after 3 steps (epoch 300)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "Ywv1nq1ZlZ09",
        "outputId": "60123347-1a97-4f4b-cdd2-5b98d29e08b3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uttci79RlZ0_"
      },
      "source": [
        "It works! Now lets see if it generalized to the test question:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlnW2U-plZ1C"
      },
      "source": [
        "## More Tasks\n",
        "\n",
        "Now that we know we can train a CA for one task, will it work on others?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzVQKw24lZ1C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate(tasks):\n",
        "    result = []\n",
        "    predictions = []\n",
        "    for idx, task in tqdm(tasks.items()):\n",
        "        if input_output_shape_is_same(task):\n",
        "            model, _, _ = solve_task(task[\"train\"])\n",
        "            pred = predict(model, task[\"test\"])\n",
        "            score = calk_score(task[\"test\"], pred)\n",
        "        else:\n",
        "            pred = [el[\"input\"] for el in task[\"test\"]]\n",
        "            score = [0] * len(task[\"test\"])\n",
        "\n",
        "        predictions.append(pred)\n",
        "        result.append(score)\n",
        "    return result, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-tm9tpplZ1D",
        "outputId": "89e07741-4a21-40af-fdad-3d89d369760f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# train_result, train_predictions = evaluate(train_tasks)\n",
        "# train_solved = [any(score) for score in train_result]\n",
        "\n",
        "# total = sum([len(score) for score in train_result])\n",
        "# print(f\"solved : {sum(train_solved)} from {total} ({sum(train_solved)/total})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_result1, train_predictions1 = evaluate(eval_tasks)\n",
        "train_solved1 = [any(score) for score in train_result1]\n",
        "\n",
        "total1 = sum([len(score) for score in train_result1])\n",
        "print(f\"solved : {sum(train_solved1)} from {total1} ({sum(train_solved1)/total1})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_true(boolean_list):\n",
        "    count = 0\n",
        "    for element in boolean_list:\n",
        "        if element:\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "count_true(train_solved1)\n",
        "print(count_true(train_solved1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5qBRe4YlZ1D"
      },
      "source": [
        "## Solved Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_true(boolean_list):\n",
        "    count = 0\n",
        "    for element in boolean_list:\n",
        "        if element:\n",
        "            count += 1\n",
        "    return count\n",
        "\n",
        "count_true(train_solved1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_accuracy(oup, pred):\n",
        "    r, c = len(oup), len(oup[0])\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            total += 1\n",
        "            if oup[i][j] == pred[i][j]:\n",
        "                correct += 1\n",
        "    return correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lascpkUklZ1E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "global model_failure\n",
        "global model_success\n",
        "global total_accuracy\n",
        "global accuracy100\n",
        "global accuracy95\n",
        "global accuracy90\n",
        "global accuracy80a\n",
        "global accuracy80b\n",
        "\n",
        "total_accuracy = 0\n",
        "model_failure = 0\n",
        "model_success = 0\n",
        "accuracy100 = 0\n",
        "accuracy95 = 0\n",
        "accuracy90 = 0\n",
        "accuracy80a = 0\n",
        "accuracy80b = 0\n",
        "\n",
        "for task, prediction, solved in tqdm(zip(eval_tasks.values(), train_predictions1, train_solved1)):\n",
        "    # if solved:\n",
        "    for i in range(len(task['test'])):\n",
        "        # We have considered a task oly if the dimensions of output and prediction are same\n",
        "        if (len(prediction[i]) == len(task['test'][i]['output'])) and (len(prediction[i][0]) == len(task['test'][i]['output'][0])):\n",
        "            acc = get_accuracy(np.array(task['test'][i]['output']), np.array(prediction[i]))\n",
        "            print(\"Accuracy: \", acc)\n",
        "            if (acc == 1.0):\n",
        "                accuracy100 += 1\n",
        "            elif (acc >= 0.95):\n",
        "                accuracy95 += 1\n",
        "            elif (acc >= 0.9):\n",
        "                accuracy90 += 1\n",
        "            elif (acc >= 0.8):\n",
        "                accuracy80a += 1\n",
        "            else:\n",
        "                accuracy80b += 1\n",
        "            \n",
        "            total_accuracy += acc\n",
        "            plot_sample(task['test'][i], prediction[i])\n",
        "            model_success += 1\n",
        "        else:\n",
        "            model_failure += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Total Accuracy: \", total_accuracy / model_success)\n",
        "print(\"Accuracy 100: \", accuracy100)\n",
        "print(\"Accuracy 95 - 100: \", accuracy95)\n",
        "print(\"Accuracy 90 - 95: \", accuracy90)\n",
        "print(\"Accuracy 80 - 90: \", accuracy80a)\n",
        "print(\"Accuracy < 80: \", accuracy80b)\n",
        "print(\"Model runs successfully for \", model_success, \"tasks\")\n",
        "print(\"Model fails for \", model_failure, \"tasks\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
